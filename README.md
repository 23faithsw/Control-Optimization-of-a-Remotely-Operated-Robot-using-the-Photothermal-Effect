# A Study on Remotely Controlled Robots and Optimized Control Models Using the Photothermal Effect
[ì—´ì‹œìŠ¤í…œí•´ì„] íŒ€ í”„ë¡œì íŠ¸(ë…¼ë¬¸ ì‘ì„±)

-----

## Research Topic: Control Optimization of a Remotely Operated Robot using the Photothermal Effect

## Research Methods

  * Building a simulation environment using **PyBullet**.
  * Implementing **Reinforcement Learning** using the **SAC (Soft Actor-Critic)** deep learning model.

## Key Results

  * **(Attach TensorBoard training graph screenshot here)**
  * <img width="563" height="362" alt="rew_mean" src="https://github.com/user-attachments/assets/333efae9-a4a0-4f69-a14d-4703a7f6a8d0" />
  * <img width="843" height="363" alt="enf" src="https://github.com/user-attachments/assets/c32c215f-efb5-436c-b20f-e265a68ee316" />
  * <img width="640" height="364" alt="enf_coef_loss" src="https://github.com/user-attachments/assets/b9fb8526-8a6b-44e1-bb4b-2121294d7207" />



      * *Description: The training curve (e.g., `rollout/ep_rew_mean`) shows the learning progress over 500k+ steps.*
  * **(Attach final optimized light pattern heatmap screenshot here)**
  * <img width="1858" height="1053" alt="ë°œí‘œìš© ê·¸ë˜í”„" src="https://github.com/user-attachments/assets/4d6f47b8-83ef-4579-8db9-e9277e630e12" />

      * *Description: The final heatmap visualizes the optimized light actuation pattern learned by the SAC agent.*

## ğŸš€ How to Run

### 1. Install Dependencies

```bash
pip install gymnasium stable-baselines3 pybullet shimmy numpy matplotlib\
```

### 2. Train the Agent

```bash
python train_final.py
```
Training logs will be saved in the final_logs directory.

### 3. Verify & Visualize Results

```bash
python verify_emergence.py
```
This script loads the trained model and generates performance analysis graphs.
